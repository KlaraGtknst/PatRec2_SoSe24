{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jp3kCz-GxYYl"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false
        },
        "id": "iUb3rSQQxYY9"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "from sklearn import datasets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "szVnaw9RxYZB"
      },
      "source": [
        "\n",
        "Whenever you look at some source of data which somehow has the form of $\\textit{clusters}$ in a d-dimensional input space. Our goal will be to identify the clusters and find a representative mean-value.\n",
        "\n",
        "In the simple k-mean algorithm the number of Clusters **K** should be choosen in advantage and the partition of the data points into sets will be done by minimization of the total sum of squared distances from each point to the mean of its assigned cluster."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s6cBwhJSxYZE"
      },
      "source": [
        "def get_data(n_samples=2000, n_clusters=4, cluster_std=.4, rs=0):\n",
        "    return datasets.make_blobs(n_samples=n_samples, centers=n_clusters, cluster_std=cluster_std, random_state=rs)[0]\n",
        "\n",
        "X = get_data()\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.scatter(X[:,0], X[:,1], alpha = 0.5, s=20)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9q5zGuVxYZG"
      },
      "source": [
        "> **Based on the template below. Implement the k-mean algorithm which contains following steps**\n",
        ">\n",
        "> - Assign each Point to the mean to which it is closest.\n",
        "> - If point's assignments has changed, recompute the mean of each cluster\n",
        "> - If no point's assignments has changed, stop and keep the clusters\n",
        "> - calculate decision boundaries\n",
        "> - Plot the data, Cluster Mean-Values and (optional) decision Boundaries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f9DA7SyBxYZI"
      },
      "source": [
        "class KMeans:\n",
        "\n",
        "    def __init__(self, n_clusters=3, max_iteration=20):\n",
        "        \"\"\"Init k-means algorithm.\n",
        "\n",
        "        Args:\n",
        "            n_clusters (int): Assumed number of clusters.\n",
        "            max_iteration (int): Maximum number of iterations.\n",
        "        \"\"\"\n",
        "        self.n_clusters = n_clusters\n",
        "        self.max_iteration = max_iteration\n",
        "\n",
        "    def _get_initial_center(self, X):\n",
        "        \"\"\"Initialize the centers.\n",
        "\n",
        "        Args:\n",
        "            n_dim (int): Dimensionality of the input samples.\n",
        "\n",
        "        Returns:\n",
        "            ndarray: A (n_cluster, n_dim) shaped array which represent the initial centers.\n",
        "\n",
        "        \"\"\"\n",
        "####################\n",
        "# Your Code Here   #\n",
        "####################\n",
        "\n",
        "    def _get_initial_center_problem(self, X):\n",
        "        return np.array([[0.01, 5], [0.0, 5.2], [0, 4.9]])\n",
        "\n",
        "    def _dist(self, X):\n",
        "        \"\"\"Compute a distance matrix between centers and datapoints based on the\n",
        "             squared euclidean distance.\n",
        "\n",
        "        Args:\n",
        "            X (ndarray): Input samples.\n",
        "\n",
        "        Returns:\n",
        "            ndarray: A (n_samples, n_clusters) shaped array representing the distance\n",
        "                        of a sample to a corresponding center.\n",
        "\n",
        "        \"\"\"\n",
        "####################\n",
        "# Your Code Here   #\n",
        "####################\n",
        "\n",
        "    def fit(self, X):\n",
        "        \"\"\"Perform k-means.\n",
        "\n",
        "        Args:\n",
        "            X (ndarray): Input samples.\n",
        "\n",
        "        \"\"\"\n",
        "        self.X_ = np.array(X)\n",
        "        # Init centers\n",
        "        self.centers = self._get_initial_center(self.X_)\n",
        "\n",
        "        for _ in range(self.max_iteration):\n",
        "\n",
        "            # E-Step according to Equation 9.2 in [Bishop2006].\n",
        "####################\n",
        "# Your Code Here   #\n",
        "####################\n",
        "\n",
        "            # M-step accoding to Equation 9.4 in [Bishop2006].\n",
        "####################\n",
        "# Your Code Here   #\n",
        "####################\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"Calculate closest cluster center.\n",
        "\n",
        "        Args:\n",
        "            X (ndarray): Input data.\n",
        "\n",
        "        Returns\n",
        "            ndarray: An (n_samples,) shaped array containing cluster indices.\n",
        "\n",
        "        \"\"\"\n",
        "####################\n",
        "# Your Code Here   #\n",
        "####################\n",
        "\n",
        "\n",
        "    def plot(self, X):\n",
        "        \"\"\"Plot the clustered data with corresponding centers.\n",
        "\n",
        "        Args:\n",
        "            X (ndarray): Input samples.\n",
        "\n",
        "        \"\"\"\n",
        "####################\n",
        "# Your Code Here   #\n",
        "####################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I2gs3hpxxYZM"
      },
      "source": [
        "clusterer = KMeans(max_iteration=10)\n",
        "clusterer.fit(X)\n",
        "clusterer.plot(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "laQ0buUsxYZO"
      },
      "source": [
        "In the previous example the choice of $K$ was given by factors outside our control. In general this wont be the case and a reasonable way to choose its value is by plotting the sum of squared errors between each point and the **mean** of its **Cluster**\n",
        "\n",
        "> Implement a function for plotting the sum of squared errors subject to values for the Parameter $K$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLn-B3FXxYZQ"
      },
      "source": [
        "def mse_cluster(X, k):\n",
        "    \"\"\"Compute the distance of all samples to its center and compute its mean.\n",
        "\n",
        "    Args:\n",
        "        X (ndarray): Input data.\n",
        "        k (int): Number of centers.\n",
        "\n",
        "    \"\"\"\n",
        "    ####################\n",
        "    # Your Code Here   #\n",
        "    ####################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qm_Zug7UxYZR"
      },
      "source": [
        "####################\n",
        "# Your Code Here   #\n",
        "####################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jHGhoGinxYZT"
      },
      "source": [
        "## k-Means for Color Compression\n",
        "\n",
        "One interesting application of clustering is in color compression within images. For example, consider follow Image whiich is stored as a three-dimensional array of size (height, width, channel) containing red/blue/green contributions as integers from 0 to 255"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MO_wmvG7xYZf"
      },
      "source": [
        "china = datasets.load_sample_image(\"china.jpg\")\n",
        "plt.figure(figsize = (10, 10))\n",
        "plt.axes(xticks=[], yticks=[])\n",
        "plt.imshow(china)\n",
        "plt.show()\n",
        "print(china.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RzSxaClFxYZg"
      },
      "source": [
        "One way we can see this set of pixels is as a cloud of points in a three-dimensional color space.\n",
        "\n",
        "> Reshape the data to `(n_samples, n_features)` and rescale the color so that they lie between 0 and 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BeeDJpbuxYZi"
      },
      "source": [
        "####################\n",
        "# Your Code Here   #\n",
        "####################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rs92cqWDxYZj"
      },
      "source": [
        "> Use follow function to visualize the pixels in color space."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w44yvyrwxYZk"
      },
      "source": [
        "def plot_pixels(data, title, colors = None, N = 10000):\n",
        "    if colors is None:\n",
        "        colors = data\n",
        "\n",
        "    #choose a random subset\n",
        "    rng = np.random.RandomState(0)\n",
        "    i = rng.permutation(data.shape[0])[:N]\n",
        "    colors = colors[i]\n",
        "    R, G, B = data[i].T\n",
        "\n",
        "    fig, ax = plt.subplots(1, 2, figsize = (10, 5))\n",
        "    ax[0].scatter(R, G, color = colors, marker = '.')\n",
        "    ax[0].set(xlabel = 'Red', ylabel = 'Green', xlim = (0, 1), ylim = (0,1))\n",
        "\n",
        "    ax[1].scatter(R, B, color = colors, marker = '.')\n",
        "    ax[1].set(xlabel = 'Red', ylabel = 'Blue', xlim = (0, 1), ylim = (0,1))\n",
        "\n",
        "    fig.suptitle(title, size = 15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_sMAlAlexYZl"
      },
      "source": [
        "plot_pixels(data, title = 'Input color space: 16 million possible colors')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qV-RHYtwxYZm"
      },
      "source": [
        "> Now reduce these 16 Million color to just 16, using a k-means clustering across the pixel space."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DSzZsudgxYZn"
      },
      "source": [
        "####################\n",
        "# Your Code Here   #\n",
        "####################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBBonRKJxYZp"
      },
      "source": [
        "> Show the resulting Image-data with the new colors in the image space."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HylVCFXfxYZq"
      },
      "source": [
        "####################\n",
        "# Your Code Here   #\n",
        "####################"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}