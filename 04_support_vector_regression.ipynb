{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sd9-Zd2cfDg6"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "S-aJC4B8fDg7"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from scipy.optimize import minimize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "s421zyyPfDg7"
      },
      "outputs": [],
      "source": [
        "def get_simple():\n",
        "    X = np.linspace(-3, 3, 11)\n",
        "    y = np.sin(X)\n",
        "    y+=np.random.randn(11)*.2\n",
        "    return X, y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t3NPUjZcfDg8"
      },
      "source": [
        "### **1. Training of SVRs via Constrained Optimization** <a class=\"anchor\" id=\"optim\"></a>\n",
        "\n",
        "Throughout this notebook, we assume $\\mathbf{X} \\in \\mathbb{R}^{N \\times D}$ as $N \\times D$ matrix of training examples and $\\mathbf{t} \\in \\mathbb{R}^N$ as $N$-dimensional vector of training targets.\n",
        "To express the dual SVR in standard form, we express the kernel matrix $K \\in \\mathbb{R}^{NxN}$ such that each entry is $K_{ij} = k(\\mathbf{x}_i , \\mathbf{x}_j)$.\n",
        "\n",
        "The dual form of the SVR was introduced as:\n",
        "\n",
        "  \\begin{align*}\n",
        "  \\widetilde{L}(\\mathbf a,\\widehat{\\mathbf a}) =& - \\frac{1}{2}  \\sum_{n=1}^N  \\sum_{m=1}^N (a_n - \\widehat a _n) (a_m - \\widehat a _m)k(\\mathbf x_n,\\mathbf x_m)\\\\ &- \\epsilon  \\sum_{n=1}^N (a_n + \\widehat a _n) +  \\sum_{m=1}^N (a_n - \\widehat a _n) t_n\n",
        "  \\end{align*}\n",
        "\n",
        "\n",
        "> To simplify the mathematical procedure, transform it first into matrix multiplication form!\n",
        "\n",
        "  \\begin{align*}\n",
        "  \\widetilde{L}(\\mathbf a,\\widehat{\\mathbf a}) =& - \\frac{1}{2}  (\\mathbf a - \\widehat{\\mathbf a})^T \\mathbf K (\\mathbf a - \\widehat{\\mathbf a})\\\\ &- \\epsilon  (\\mathbf a + \\widehat{\\mathbf a})^T * \\mathbf {1} +   (\\mathbf a - \\widehat{\\mathbf a})^T \\mathbf t\n",
        "  \\end{align*}\n",
        "\n",
        "The optimization objective is given by:\n",
        "\\begin{align}\n",
        "\\max_{\\boldsymbol{a}}\\widetilde{L}(\\mathbf a,\\widehat{\\mathbf a})\n",
        "\\end{align}\n",
        "subject to\n",
        "\\begin{align}\n",
        "  0 \\leqslant a_n \\leqslant C\\\\\n",
        "  0 \\leqslant \\widehat a_n \\leqslant C\n",
        "\\end{align}\n",
        "\n",
        "Once, we have found the optimum $\\boldsymbol{a}$, the prediction function of the SVR is given by\n",
        "\\begin{equation}\n",
        "y(\\mathbf x) = \\sum_{n=1}^N (a_n- \\widehat a _n)k (\\mathbf x, \\mathbf x _n) +b\n",
        "\\end{equation}\n",
        "where $b \\in \\mathbb{R}$ is the bias parameter.\n",
        "\n",
        "We can estimate $b$ by considering a data point for which $0 < a_n < C$, which must have $\\xi_n = 0$. Therefore this point must satisfy $\\epsilon + y_n - t_n = 0$.\n",
        "\\begin{equation}\n",
        "b = \\frac{1}{N_\\mathcal{M}} \\sum_{n \\in \\mathcal{M}} \\left( t_n - \\epsilon - \\sum_{m \\in \\mathcal{S}} (a_m- \\widehat a _m)k (\\mathbf x_n, \\mathbf x _m)\\right).\n",
        "\\end{equation}\n",
        "Analogous results can be obtained by considering a point for which $0 < \\widehat a_n < C$. $\\mathcal{S} \\subseteq \\{1, \\dots, N\\}$ denotes the set of support vectors and $\\mathcal{M} \\subseteq \\{1, \\dots, N\\}$ denotes the set of support vectors lying\n",
        "on the margin with $N_\\mathcal{M} = |\\mathcal{M}|$.\n",
        "\n",
        "> Below, implement a SVR for a simple regression problem by solving the dual problem above.\n",
        "> For optimization make use of `scipy` and its [Optimization Module](https://docs.scipy.org/doc/scipy/reference/tutorial/optimize.html#sequential-least-squares-programming-slsqp-algorithm-method-slsqp)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "oJ5e1emUfDg8"
      },
      "outputs": [],
      "source": [
        "class RBFKernel:\n",
        "    def __init__(self, gamma=1):\n",
        "        \"\"\"Computes RBF kernel matrix between X_1 and X_2.\n",
        "\n",
        "        Args:\n",
        "            gamma (float): Hyperparameter of RBF kernel.\n",
        "        \"\"\"\n",
        "        self.gamma = gamma\n",
        "\n",
        "    def __call__(self, X_1, X_2):\n",
        "        \"\"\"Computes the kernel matrix.\n",
        "\n",
        "        Args:\n",
        "            X_1 (array-like): Input samples in shape (N, D).\n",
        "            X_2 (array-like): Input samples in shape (N, D).\n",
        "\n",
        "        Returns:\n",
        "            ndarray: Kernel matrix of shape shape (N, M)\n",
        "        \"\"\"\n",
        "        return np.exp(-self.gamma * np.sum((X_1[:, None] - X_2[None]) ** 2, axis=2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "pfKW1BokfDg9"
      },
      "outputs": [],
      "source": [
        "class SVR:\n",
        "    def __init__(self, kernel_func, eps=0.2, C=1.0, random_state=42):\n",
        "        \"\"\"Implementation of a C-SVM for regression.\n",
        "        Args:\n",
        "            C (float): Regularization parameter. The strength of the regularization is inversely\n",
        "                proportional to C. Must be strictly positive. (default=1.0)\n",
        "            eps (float): ...\n",
        "            kernel_func (callable): Specifies the kernel type to be used in the algorithm.\n",
        "            random_state (int): Random state to ensure reproducibility when initializing  a values.\n",
        "        \"\"\"\n",
        "        self.C = C\n",
        "        self.eps = eps\n",
        "        self.kernel_func = kernel_func\n",
        "        self.random_state = random_state\n",
        "        np.random.seed(self.random_state)\n",
        "\n",
        "\n",
        "    def fit(self, X, t):\n",
        "        \"\"\"Fit the SVM model according to the given training data.\n",
        "\n",
        "        Args:\n",
        "            X (array-like): Training samples of shape (N, D).\n",
        "            t (array-like): Training targets of shape (N).\n",
        "\n",
        "        Returns:\n",
        "            self: The fitted SVM object.\n",
        "        \"\"\"\n",
        "        K = self.kernel_func(X, X)\n",
        "        \n",
        "        \n",
        "        # Optimization\n",
        "        # Step 1: Define the loss function and its gradient.\n",
        "        def loss(a):\n",
        "            # Compute loss for given a.\n",
        "            a_hat = a[:len(a)//2]\n",
        "            a_normal = a[len(a)//2:]\n",
        "            diff_a = (a_normal - a_hat)\n",
        "            return - 0.5 * diff_a.T @ K @ diff_a - self.eps * (a_normal + a_hat).T @ np.ones_like(diff_a) + diff_a.T @ t  # dual form\n",
        "\n",
        "        def jac(a):\n",
        "            # Compute gradient of loss function w.r.t. a. -> 2*N lang; gradient != jacobian\n",
        "            # concat grad w.r.t a_hat and a_normal\n",
        "            a_hat = a[:len(a)//2]\n",
        "            a_normal = a[len(a)//2:]\n",
        "          \n",
        "            deriv_t_a = -a_normal.T @ K  + 0.5 * a_hat.T @ K + 0.5 * a_hat @ K - self.eps + t\n",
        "            deriv_t_a_hat = a_normal.T @ K - a_hat @ K - self.eps - t\n",
        "            jac = np.concatenate([deriv_t_a_hat, deriv_t_a])\n",
        "            return jac\n",
        "\n",
        "        # Step 2: Define the Constraints.\n",
        "        # We need to write the contraints in matrix notation:\n",
        "        # - for inequalities: Ax <= b\n",
        "        # - for eqalities cx = d\n",
        "        # Note that x = a in our example.\n",
        "        # 'fun' in the constraints needs to be adapted such that\n",
        "        # 0 <= lambda a: ....\n",
        "\n",
        "        # Set up the constraints:\n",
        "        # Example: {'type': 'eq', 'fun': lambda a: a**2, 'jac': lambda a: 2*a}\n",
        "        \n",
        "        constraints = [{'type': 'ineq', 'fun': lambda a: a, 'jac': lambda a: np.eye(len(a))}]  # 0 <= a_hat\n",
        "        #constraints += [{'type': 'ineq', 'fun': lambda a: a[len(a)//2:], 'jac': lambda a: np.eye(len(a)//2)}]  # 0 <= a_normal\n",
        "        \n",
        "        constraints += [{'type': 'ineq', 'fun': lambda a: self.C - a, 'jac': lambda a: -np.eye(len(a))}]   # a_hat <= C\n",
        "        #constraints += [{'type': 'ineq', 'fun': lambda a: self.C - a[len(a)//2:], 'jac': lambda a: -np.eye(len(a)//2)}]   # a_normal <= C\n",
        "\n",
        "        #constraints += [{'type': 'eq', 'fun': lambda a: np.sum(a[len(a)//2:] - a[:len(a)//2]), 'jac': lambda a: np.concatenate([-np.ones(len(a)//2), np.ones(len(a)//2)])}]  # sum(a_normal - a_hat) = 0\n",
        "\n",
        "\n",
        "        # Optimize the a vector.\n",
        "        a0 = np.random.rand(2 * len(X))  # initial guess\n",
        "        self.a_ = minimize(loss, a0, jac=jac, constraints=constraints, method='SLSQP').x\n",
        "        self.a_[np.isclose(self.a_, 0)] = 0  # zero out nearly zeros\n",
        "        self.a_[np.isclose(self.a_, self.C)] = self.C  # round the ones that are nearly C\n",
        "\n",
        "\n",
        "        # Determine indices of support vectors.\n",
        "        a_hat = self.a_[:len(self.a_)//2]\n",
        "        a_normal = self.a_[len(self.a_)//2:]\n",
        "\n",
        "        self.support_index_hat_ = np.where(a_hat == 0)[0]\n",
        "        self.support_index_normal_ = np.where(a_normal == 0)[0]\n",
        "        self.support_ = np.where((a_hat != 0) | (a_normal != 0))[0]\n",
        "        # Determine indices of support vectors that lie on the margin.\n",
        "        # support vectors are those with a_hat != 0 OR a_normal != 0\n",
        "        self.on_margin_hat = np.where((a_hat != 0) & (a_hat <= self.C))[0]\n",
        "        self.on_margin_normal = np.where((a_normal != 0) & (a_normal <= self.C))[0]\n",
        "        self.on_margin_ = np.where(((a_hat != 0) | (a_normal != 0)) & ((a_hat <= self.C) | (a_normal <= self.C)))[0]\n",
        "        \n",
        "\n",
        "        # Determine bias parameter.\n",
        "        # on_margin is subset of support vectors: != 0 & <= C\n",
        "        self.b = 1/len(self.on_margin_hat) \\\n",
        "            * np.sum(t[self.on_margin_hat] \\\n",
        "                     - self.eps - np.sum(a_hat[self.support_index_hat_] \\\n",
        "                                            @ K[self.support_index_hat_][:, self.on_margin_hat], axis=0))\n",
        "\n",
        "\n",
        "        # Store support vectors including their targets and a.\n",
        "        self.support_vectors = X[self.support_]\n",
        "        self.support_targets = t[self.support_]\n",
        "        self.support_a = self.a_[self.support_]\n",
        "\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"Perform regression on samples in X.\n",
        "\n",
        "        Args:\n",
        "            X (array-like): Input samples whose targets are to be predicted.\n",
        "\n",
        "        Returns:\n",
        "            y (array-like): Predicted target of samples in X.\n",
        "        \"\"\"\n",
        "\n",
        "        a_hat = self.a_[:len(self.a_)//2]\n",
        "        a_normal = self.a_[len(self.a_)//2:]\n",
        "        K = self.kernel_func(X.reshape(-1,1), self.support_vectors)\n",
        "        return (a_normal - a_hat).reshape(1,-1) @ K + self.b "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QywmWnXwfDg9"
      },
      "source": [
        "> Train the SVR on the given dataset and plot its support vectors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "qxu1w6IBfDg9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(11,)\n",
            "[-2.36208683 -3.05951633 -3.29014187 -3.25097797 -2.78027359 -1.3850467\n",
            "  0.61482754  2.00702906  2.44172068  2.28312071  1.59174661]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x14cbc7d90>"
            ]
          },
          "execution_count": 80,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "X, y = get_simple()\n",
        "print(X.shape)\n",
        "\n",
        "svr = SVR(RBFKernel(gamma=1), eps=0.2, C=1.0)\n",
        "svr.fit(X.reshape(-1,1), y)\n",
        "#FIXME: sign is wrong and scale is too large\n",
        "y_pred = -svr.predict(X).squeeze()\n",
        "print(y_pred)\n",
        "plt.scatter(X, y)\n",
        "plt.scatter(X, y_pred, color='red')\n",
        "plt.legend(['Data', 'Prediction'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
