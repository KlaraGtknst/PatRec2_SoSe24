{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "be76nCz18rxB"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Bp9N3ZF8rxH"
      },
      "source": [
        "import numpy as np\n",
        "import pylab as plt\n",
        "\n",
        "from sklearn.datasets import make_moons, make_circles, fetch_openml"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A50KpVAL8rxK"
      },
      "source": [
        "# Vanilla PCA for comparison\n",
        "class PCA:\n",
        "    def __init__(self, n_components):\n",
        "        self.n_components = n_components\n",
        "\n",
        "    def fit(self, X):\n",
        "        X = np.array(X)\n",
        "        N, D = X.shape\n",
        "        self.mu_ = np.mean(X, axis=0)\n",
        "        S = ((X-self.mu_).T @ (X-self.mu_)) / N\n",
        "        self.lmbdas_, self.U_ = np.linalg.eigh(S)\n",
        "        sort_idx = np.argsort(-self.lmbdas_)\n",
        "        self.lmbdas_ = self.lmbdas_[sort_idx]\n",
        "        self.U_ = self.U_[:, sort_idx]\n",
        "        self._determine_M()\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        B = self.U_[:, :self.M_]\n",
        "        X = np.array(X)\n",
        "        Z = (X-self.mu_) @ B\n",
        "        return Z\n",
        "\n",
        "    def inverse_transform(self, Z):\n",
        "        B = self.U_[:, :self.M_]\n",
        "        Z = np.array(Z)\n",
        "        X = Z @ B.T\n",
        "        X += self.mu_\n",
        "        return X\n",
        "\n",
        "    def _determine_M(self):\n",
        "        if self.n_components >= 1:\n",
        "            self.M_ = self.n_components\n",
        "        elif 0 < self.n_components < 1:\n",
        "            cum_lmbdas = np.cumsum(self.lmbdas_ / np.sum(self.lmbdas_))\n",
        "            self.M_ = np.argmax(cum_lmbdas >= self.n_components) + 1\n",
        "        else:\n",
        "            raise ValueError('Invalid `n_components` parameter.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0QLwm4B08rxN"
      },
      "source": [
        "# **Principal Component Analysis - Extensions**\n",
        "In this notebook, we will implement two extensions to the *principal component analysis* (PCA) algorithm.\n",
        "First, we will implement the high-dimensional data version, which takes care of the case where the number of samples $N$ is smaller than the number of features $D$. Subsquently, we will implement the kernel version which allows to obtain projected data of a PCA in an unknown feature space.\n",
        "\n",
        "Mathematically, we denote an obtained data set consisting of $N$ samples as a matrix $\\mathbf{X} \\in \\mathbb{R}^{N \\times D}$, where the $n$-th row of this matrix represents the $n$-th samples being a $D$-dimensional feature vector: $\\mathbf{x}_n = (x_{n1}, \\dots, x_{nD})^\\mathrm{T}$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l0isZAwi8rxO"
      },
      "source": [
        "## **High-dimensional PCA**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ksuAY0z58rxP"
      },
      "source": [
        "X_img_all, y_img_all = fetch_openml('mnist_784', version=1, return_X_y=True)\n",
        "# convert from pandas to numpy if necessary\n",
        "\n",
        "idx = np.random.choice(range(len(X_img_all)), replace=False, size=20)\n",
        "X_img = X_img_all[idx]\n",
        "y_img = y_img_all[idx]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EmpbOyrN8rxR"
      },
      "source": [
        "> A corresponding class for high-dimensional PCA is to be implemented below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzN7gDwH8rxS"
      },
      "source": [
        "class HighDimPCA(PCA):\n",
        "    \"\"\" This class implements the principal component analysis for N < D,\n",
        "        where N is the number of samples and D is the number of features.\n",
        "    \"\"\"\n",
        "    def fit(self, X):\n",
        "####################\n",
        "# Your Code Here   #\n",
        "####################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i421GGkn8rxS"
      },
      "source": [
        "> Compare its runtime against the vanilla PCA implementation (e.g., using `%timeit`)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dZ7ocB68rxU"
      },
      "source": [
        "# Example for timeit\n",
        "%timeit np.dot(5, 5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8BWw34G8rxW"
      },
      "source": [
        "####################\n",
        "# Your Code Here   #\n",
        "####################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NxGwAkvJ8rxZ"
      },
      "source": [
        "## **Kernel PCA**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2V-i2tN8rxZ"
      },
      "source": [
        "X_moons, y_moons = make_moons(n_samples=100, random_state=0)\n",
        "X_circles, y_circles = make_circles(n_samples=200, factor=.2, noise=.1)\n",
        "\n",
        "plt.subplot(121)\n",
        "plt.scatter(X_moons[:, 0], X_moons[:, 1], c=y_moons)\n",
        "\n",
        "plt.subplot(122)\n",
        "plt.scatter(X_circles[:, 0], X_circles[:, 1], c=y_circles)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dE5_w9uU8rxa"
      },
      "source": [
        "> Implement a standard PCA algorithm using sklearn. Reduce the number of components and try to explain why standard PCA is not working here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yeO50wpR8rxb"
      },
      "source": [
        "####################\n",
        "# Your Code Here   #\n",
        "####################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rvt026b88rxb"
      },
      "source": [
        "> Implement the Gaussian kernel given by: $$k_\\sigma(\\mathbf{x},\\mathbf{x}^{\\prime})=\\exp(-\\left\\Vert \\mathbf{x}-\\mathbf{x}^{\\prime}\\right\\Vert ^{2}/\\sigma) $$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hU9PaPrY8rxb"
      },
      "source": [
        "class GaussianKernel:\n",
        "    def __init__(self, sigma):\n",
        "####################\n",
        "# Your Code Here   #\n",
        "####################\n",
        "\n",
        "    def __call__(self, x, y):\n",
        "####################\n",
        "# Your Code Here   #\n",
        "####################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kwyguWAr8rxc"
      },
      "source": [
        "> A corresponding class for the KernelPCA is to be implemented below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9IPMamJw8rxc"
      },
      "source": [
        "class KernelPCA:\n",
        "    \"\"\"This class implements the kernel version of the principal component analysis.\n",
        "\n",
        "    Args:\n",
        "        n_comonents (int): Number of components to consider.\n",
        "\n",
        "    \"\"\"\n",
        "    def __init__(self, n_components, kernel_func):\n",
        "        self.n_components = n_components\n",
        "        self.kernel_func = kernel_func\n",
        "\n",
        "    def fit(self, X):\n",
        "        \"\"\"Determine required parameters of the Kernel PCA.\n",
        "\n",
        "        Args:\n",
        "            X (array-like): Input samples.\n",
        "\n",
        "        Returns:\n",
        "            The fitted PCA object.\n",
        "        \"\"\"\n",
        "####################\n",
        "# Your Code Here   #\n",
        "####################\n",
        "\n",
        "    def get_gram_matrix(self, X1, X2=None):\n",
        "        \"\"\" Computes the gram marix.\n",
        "\n",
        "        Args:\n",
        "            X (ndarray): Samples in the input space.\n",
        "\n",
        "        Returns\n",
        "            The gram matrix for all samples.\n",
        "        \"\"\"\n",
        "####################\n",
        "# Your Code Here   #\n",
        "####################\n",
        "\n",
        "    def center_gram_matrix(self, K):\n",
        "        \"\"\" Computes the gram matrix with centered features.\n",
        "\n",
        "        Args:\n",
        "            K (ndarray): Gram matrix computed by a kernel.\n",
        "\n",
        "        Returns\n",
        "            Transformed gram matrix with mean zero in the projection space.\n",
        "        \"\"\"\n",
        "####################\n",
        "# Your Code Here   #\n",
        "####################\n",
        "\n",
        "    def transform(self, X):\n",
        "        \"\"\" Transforms samples from the D-dimensional input space into\n",
        "            the M-dimensional projection space.\n",
        "\n",
        "        Args:\n",
        "            X (ndarray): Samples in the input space.\n",
        "\n",
        "        Returns\n",
        "            Transformed samples in the projection space.\n",
        "        \"\"\"\n",
        "####################\n",
        "# Your Code Here   #\n",
        "####################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K2i5PLZO8rxd"
      },
      "source": [
        "> Apply the Kernel PCA to the two-dimensional toy data sets and plot the features space projected on some principal components."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EYg_9ZHW8rxd"
      },
      "source": [
        "####################\n",
        "# Your Code Here   #\n",
        "####################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jo9yCA2C8rxe"
      },
      "source": [
        "####################\n",
        "# Your Code Here   #\n",
        "####################"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}